{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build graph using TF operations\n",
    "import tensorflow as tf\n",
    "\n",
    "x_train = [1,2,3]\n",
    "y_train = [1,2,3]  #마지막에 값을 넣어서 비교하고싶다면 메모리생성하는 placeholder 사용가능 : 3번째 칸 참고\n",
    "\n",
    "\n",
    "W= tf.Variable(tf.random_normal([1]), name='weight')#tensorflow가 변형시킨다, 정규분포난수값 넣기\n",
    "b=tf.Variable(tf.random_normal([1]),name='bias')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hypothesis = x_train*W +b \n",
    "\n",
    "#costfunction\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  0 , cost:  2.90174 [-0.28107321] [ 1.21766269]\n",
      "step:  40 , cost:  0.263768 [ 0.39808187] [ 1.35293758]\n",
      "step:  80 , cost:  0.217396 [ 0.45841992] [ 1.23099947]\n",
      "step:  120 , cost:  0.17932 [ 0.50817448] [ 1.11803389]\n",
      "step:  160 , cost:  0.147913 [ 0.55331659] [ 1.01541638]\n",
      "step:  200 , cost:  0.122007 [ 0.59431499] [ 0.92221737]\n",
      "step:  240 , cost:  0.100639 [ 0.63155043] [ 0.83757269]\n",
      "step:  280 , cost:  0.0830124 [ 0.66536808] [ 0.76069707]\n",
      "step:  320 , cost:  0.0684733 [ 0.696082] [ 0.6908772]\n",
      "step:  360 , cost:  0.0564806 [ 0.72397673] [ 0.62746572]\n",
      "step:  400 , cost:  0.0465884 [ 0.74931121] [ 0.56987447]\n",
      "step:  440 , cost:  0.0384288 [ 0.77232045] [ 0.51756912]\n",
      "step:  480 , cost:  0.0316982 [ 0.79321778] [ 0.47006458]\n",
      "step:  520 , cost:  0.0261464 [ 0.81219715] [ 0.42692012]\n",
      "step:  560 , cost:  0.021567 [ 0.82943451] [ 0.38773561]\n",
      "step:  600 , cost:  0.0177897 [ 0.84508961] [ 0.3521477]\n",
      "step:  640 , cost:  0.014674 [ 0.85930794] [ 0.31982622]\n",
      "step:  680 , cost:  0.0121039 [ 0.87222123] [ 0.29047123]\n",
      "step:  720 , cost:  0.00998399 [ 0.88394928] [ 0.26381063]\n",
      "step:  760 , cost:  0.00823536 [ 0.89460087] [ 0.23959705]\n",
      "step:  800 , cost:  0.00679299 [ 0.90427476] [ 0.21760584]\n",
      "step:  840 , cost:  0.00560324 [ 0.91306084] [ 0.19763312]\n",
      "step:  880 , cost:  0.00462187 [ 0.92104053] [ 0.17949352]\n",
      "step:  920 , cost:  0.00381237 [ 0.92828763] [ 0.1630189]\n",
      "step:  960 , cost:  0.00314466 [ 0.93486971] [ 0.14805642]\n",
      "step:  1000 , cost:  0.0025939 [ 0.94084758] [ 0.13446729]\n",
      "step:  1040 , cost:  0.00213959 [ 0.94627678] [ 0.12212539]\n",
      "step:  1080 , cost:  0.00176486 [ 0.95120782] [ 0.11091621]\n",
      "step:  1120 , cost:  0.00145575 [ 0.95568609] [ 0.1007359]\n",
      "step:  1160 , cost:  0.00120079 [ 0.95975351] [ 0.09148997]\n",
      "step:  1200 , cost:  0.000990475 [ 0.96344739] [ 0.08309262]\n",
      "step:  1240 , cost:  0.000817003 [ 0.96680236] [ 0.07546604]\n",
      "step:  1280 , cost:  0.000673909 [ 0.96984953] [ 0.0685394]\n",
      "step:  1320 , cost:  0.000555873 [ 0.97261679] [ 0.0622485]\n",
      "step:  1360 , cost:  0.000458519 [ 0.97513008] [ 0.05653509]\n",
      "step:  1400 , cost:  0.000378209 [ 0.97741276] [ 0.05134606]\n",
      "step:  1440 , cost:  0.00031197 [ 0.97948581] [ 0.04663333]\n",
      "step:  1480 , cost:  0.000257328 [ 0.98136884] [ 0.0423531]\n",
      "step:  1520 , cost:  0.000212261 [ 0.98307884] [ 0.03846573]\n",
      "step:  1560 , cost:  0.000175085 [ 0.9846319] [ 0.03493519]\n",
      "step:  1600 , cost:  0.000144419 [ 0.9860425] [ 0.03172871]\n",
      "step:  1640 , cost:  0.000119126 [ 0.98732352] [ 0.02881653]\n",
      "step:  1680 , cost:  9.82601e-05 [ 0.98848706] [ 0.02617163]\n",
      "step:  1720 , cost:  8.10509e-05 [ 0.98954374] [ 0.02376955]\n",
      "step:  1760 , cost:  6.68545e-05 [ 0.99050361] [ 0.02158772]\n",
      "step:  1800 , cost:  5.51455e-05 [ 0.99137515] [ 0.01960628]\n",
      "step:  1840 , cost:  4.54873e-05 [ 0.99216676] [ 0.01780673]\n",
      "step:  1880 , cost:  3.75201e-05 [ 0.99288571] [ 0.01617239]\n",
      "step:  1920 , cost:  3.09493e-05 [ 0.99353868] [ 0.01468803]\n",
      "step:  1960 , cost:  2.55285e-05 [ 0.99413174] [ 0.0133399]\n",
      "step:  2000 , cost:  2.10572e-05 [ 0.99467039] [ 0.01211551]\n"
     ]
    }
   ],
   "source": [
    "#run and update \n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.-기존 덤프변수삭제 및 같은 변수이름의 값 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line\n",
    "for step in range(2001): # minimize값 찾기 2001번 수행\n",
    "    sess.run(train)\n",
    "    if step % 40 == 0:\n",
    "        print(\"step: \",step, \", cost: \",sess.run(cost), sess.run(W), sess.run(b))\n",
    "        \n",
    "'''\n",
    "sess.run(train)할때마다 minimize함수가 사용되면서 미분이 실행되고 cost가 떨어지게 된다. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 , cost:  2.32191 [ 0.91110301] [ 0.18841425]\n",
      "40 , cost:  0.0948406 [ 1.19925547] [ 0.38059941]\n",
      "80 , cost:  0.0723317 [ 1.17401683] [ 0.47174358]\n",
      "120 , cost:  0.0551649 [ 1.15197015] [ 0.55133915]\n",
      "160 , cost:  0.0420724 [ 1.13271666] [ 0.62085038]\n",
      "200 , cost:  0.0320872 [ 1.11590266] [ 0.68155485]\n",
      "240 , cost:  0.0244718 [ 1.10121858] [ 0.73456866]\n",
      "280 , cost:  0.0186638 [ 1.088395] [ 0.78086603]\n",
      "320 , cost:  0.0142343 [ 1.077196] [ 0.82129776]\n",
      "360 , cost:  0.010856 [ 1.06741583] [ 0.85660726]\n",
      "400 , cost:  0.0082795 [ 1.05887485] [ 0.88744318]\n",
      "440 , cost:  0.00631451 [ 1.05141604] [ 0.91437238]\n",
      "480 , cost:  0.00481588 [ 1.04490185] [ 0.93789005]\n",
      "520 , cost:  0.0036729 [ 1.03921318] [ 0.95842797]\n",
      "560 , cost:  0.00280119 [ 1.03424513] [ 0.97636414]\n",
      "600 , cost:  0.00213637 [ 1.02990639] [ 0.99202794]\n",
      "640 , cost:  0.00162933 [ 1.02611756] [ 1.00570726]\n",
      "680 , cost:  0.00124265 [ 1.02280879] [ 1.01765311]\n",
      "720 , cost:  0.000947728 [ 1.01991892] [ 1.02808571]\n",
      "760 , cost:  0.000722792 [ 1.01739538] [ 1.03719699]\n",
      "800 , cost:  0.000551249 [ 1.01519156] [ 1.04515362]\n",
      "840 , cost:  0.000420416 [ 1.0132668] [ 1.05210245]\n",
      "880 , cost:  0.000320639 [ 1.01158607] [ 1.05817056]\n",
      "920 , cost:  0.000244543 [ 1.01011813] [ 1.06346989]\n",
      "960 , cost:  0.000186503 [ 1.00883627] [ 1.06809807]\n",
      "1000 , cost:  0.000142234 [ 1.00771666] [ 1.07214046]\n",
      "1040 , cost:  0.000108477 [ 1.00673902] [ 1.07566988]\n",
      "1080 , cost:  8.27314e-05 [ 1.00588524] [ 1.07875228]\n",
      "1120 , cost:  6.30949e-05 [ 1.00513959] [ 1.0814445]\n",
      "1160 , cost:  4.81213e-05 [ 1.00448847] [ 1.08379519]\n",
      "1200 , cost:  3.67007e-05 [ 1.00391984] [ 1.08584821]\n",
      "1240 , cost:  2.79915e-05 [ 1.00342321] [ 1.08764112]\n",
      "1280 , cost:  2.13484e-05 [ 1.00298965] [ 1.08920658]\n",
      "1320 , cost:  1.62824e-05 [ 1.00261092] [ 1.09057391]\n",
      "1360 , cost:  1.2418e-05 [ 1.00228012] [ 1.09176815]\n",
      "1400 , cost:  9.47071e-06 [ 1.00199127] [ 1.09281087]\n",
      "1440 , cost:  7.2239e-06 [ 1.00173903] [ 1.09372139]\n",
      "1480 , cost:  5.50923e-06 [ 1.00151873] [ 1.09451687]\n",
      "1520 , cost:  4.20187e-06 [ 1.00132644] [ 1.09521127]\n",
      "1560 , cost:  3.20542e-06 [ 1.00115848] [ 1.0958178]\n",
      "1600 , cost:  2.44454e-06 [ 1.00101173] [ 1.09634757]\n",
      "1640 , cost:  1.86452e-06 [ 1.00088358] [ 1.09681022]\n",
      "1680 , cost:  1.42202e-06 [ 1.00077164] [ 1.09721422]\n",
      "1720 , cost:  1.0845e-06 [ 1.00067389] [ 1.09756708]\n",
      "1760 , cost:  8.2705e-07 [ 1.00058854] [ 1.09787524]\n",
      "1800 , cost:  6.30996e-07 [ 1.00051391] [ 1.09814429]\n",
      "1840 , cost:  4.81426e-07 [ 1.00044894] [ 1.09837925]\n",
      "1880 , cost:  3.6704e-07 [ 1.00039208] [ 1.09858453]\n",
      "1920 , cost:  2.80048e-07 [ 1.00034237] [ 1.0987637]\n",
      "1960 , cost:  2.1364e-07 [ 1.0002991] [ 1.09892023]\n",
      "2000 , cost:  1.63078e-07 [ 1.00026119] [ 1.09905684]\n",
      "[ 6.10036278]\n",
      "[ 3.59970999]\n",
      "[ 2.59944868  4.59997082]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#tf.set_random_seed(777)  # for reproducibility\n",
    " \n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "W= tf.Variable(tf.random_normal([1]), name='weight')#tensorflow가 변형시킨다, 정규분포난수값 넣기\n",
    "b=tf.Variable(tf.random_normal([1]),name='bias')\n",
    "\n",
    "# Our hypothesis XW+b\n",
    "hypothesis = X * W + b\n",
    " \n",
    "#costfunction\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost) #train은 모델이다. function node\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.-기존 덤프변수삭제 및 같은 변수이름의 값 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line with new training data\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ =  \\\n",
    "         sess.run([cost, W, b, train],\n",
    "                 feed_dict={X: [1, 2, 3, 4, 5],\n",
    "                            Y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "    if step % 40 == 0:\n",
    "        print(step,\", cost: \", cost_val, W_val, b_val)\n",
    "\n",
    "# Testing our model\n",
    "print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

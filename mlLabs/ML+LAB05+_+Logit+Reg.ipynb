{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "# Lab 5 Logistic Regression Classifier\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = [[1, 2],\n",
    "          [2, 3],\n",
    "          [3, 1],\n",
    "          [4, 3],\n",
    "          [5, 3],\n",
    "          [6, 2]]\n",
    "y_data = [[0],\n",
    "          [0],\n",
    "          [0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X, W)))\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "'''\n",
    "0부터 1까지 연속적인 value나온다. 0~1\n",
    "'''\n",
    "\n",
    "# cost/loss function ->  summation and * -1/m -> reduceMean\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *  tf.log(1 - hypothesis))\n",
    "\n",
    "# derivative -> gradient \n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "\n",
    "'''\n",
    "sigmoid 0.5기준으로 0과 1을 나눈다.\n",
    "'''\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "'''\n",
    "(tf.equal(predicted, Y) - > predicted == Y  \n",
    "\n",
    "tf.cast() -> true : 1, false:0\n",
    "\n",
    "mean -> 66/99 -> 비율나옴\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.4601\n",
      "200 0.634028\n",
      "400 0.568746\n",
      "600 0.530736\n",
      "800 0.503868\n",
      "1000 0.482253\n",
      "1200 0.463487\n",
      "1400 0.446492\n",
      "1600 0.430745\n",
      "1800 0.415974\n",
      "2000 0.402029\n",
      "2200 0.388817\n",
      "2400 0.376277\n",
      "2600 0.364362\n",
      "2800 0.353035\n",
      "3000 0.342262\n",
      "3200 0.332014\n",
      "3400 0.322262\n",
      "3600 0.31298\n",
      "3800 0.304141\n",
      "4000 0.295721\n",
      "4200 0.287698\n",
      "4400 0.280048\n",
      "4600 0.272751\n",
      "4800 0.265786\n",
      "5000 0.259136\n",
      "5200 0.252781\n",
      "5400 0.246707\n",
      "5600 0.240895\n",
      "5800 0.235333\n",
      "6000 0.230006\n",
      "6200 0.2249\n",
      "6400 0.220004\n",
      "6600 0.215307\n",
      "6800 0.210797\n",
      "7000 0.206464\n",
      "7200 0.2023\n",
      "7400 0.198294\n",
      "7600 0.194439\n",
      "7800 0.190727\n",
      "8000 0.187151\n",
      "8200 0.183704\n",
      "8400 0.180378\n",
      "8600 0.177169\n",
      "8800 0.174071\n",
      "9000 0.171078\n",
      "9200 0.168185\n",
      "9400 0.165388\n",
      "9600 0.162681\n",
      "9800 0.160061\n",
      "10000 0.157525\n",
      "\n",
      "Hypothesis:  [[ 0.03418868]\n",
      " [ 0.16327268]\n",
      " [ 0.32096389]\n",
      " [ 0.77412301]\n",
      " [ 0.93490809]\n",
      " [ 0.9786154 ]] \n",
      "Correct (Y):  [[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, cost_val)\n",
    "    \n",
    "    '''\n",
    "    sess.run([cost, train] 할때마다 cost, train함수가 실행(미분)되면서 값이 떨어진다.\n",
    "    '''\n",
    "            \n",
    "            \n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    sess.run([hypothesis, predicted, accuracy]) 은 한번만 실행된다.\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
